{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ad964f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf90900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "seq_len = 10  # window size for input sequences\n",
    "data_columns = ['d1', 'd2', 'd3', 'd4', 'd5', 'd6', 'bonus']\n",
    "\n",
    "num_epochs = 100    # Epoch 100/100, Loss: 8.0247\n",
    "#vnum_epochs = 50    # Epoch 50/50, Loss: 10.7304\n",
    "# num_epochs = 25    # Epoch 25/25, Loss: 14.2781\n",
    "# num_epochs = 10    #original 10\n",
    "# learning_rate = 0.01   # Epoch 10/10, Loss: 19.3940\n",
    "learning_rate = 0.001    # original Epoch 10/10, Loss: 18.2901\n",
    "# batch size hyperparameter\n",
    "batch_size = 32\n",
    "# key hyperparameter that controls the size of the embedding vectors for categorical values\n",
    "embedding_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6630e8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data shape: (4341, 7)\n",
      "input data type: int64\n",
      "[[ 3 11 12 14 41 43 13]\n",
      " [ 8 33 36 37 39 41  9]\n",
      " [ 1  6 23 24 27 39 34]\n",
      " [ 3  9 10 13 20 43 34]\n",
      " [ 5 14 21 31 34 47 45]]\n",
      "...\n",
      "[[ 4  9 11 12 42 49 41]\n",
      " [ 7 18 23 35 48 49 19]\n",
      " [24 29 31 33 36 37 21]\n",
      " [ 3 10 12 14 36 41  1]\n",
      " [ 5 16 17 21 41 47  6]]\n",
      "Data loaded and preprocessed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Read and preprocess data\n",
    "file_path = '../data/data_all_l649.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.drop(columns=['date'])\n",
    "input_data = df[data_columns].values.astype(int)\n",
    "print(f\"input data shape: {input_data.shape}\")\n",
    "print(f\"input data type: {input_data.dtype}\")\n",
    "print(input_data[:5])  # Display first 5 rows of labels\n",
    "print('...')\n",
    "print(input_data[-5:])  # Display last 5 rows of labels\n",
    "print(\"Data loaded and preprocessed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e080d5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and set device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca01ef02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: torch.Size([4331, 10, 7]), targets shape: torch.Size([4331, 7])\n",
      "tensor([[ 3, 11, 12, 14, 41, 43, 13],\n",
      "        [ 8, 33, 36, 37, 39, 41,  9],\n",
      "        [ 1,  6, 23, 24, 27, 39, 34],\n",
      "        [ 3,  9, 10, 13, 20, 43, 34],\n",
      "        [ 5, 14, 21, 31, 34, 47, 45],\n",
      "        [ 8, 20, 21, 25, 31, 41, 33],\n",
      "        [18, 25, 28, 33, 36, 42,  7],\n",
      "        [ 7, 16, 17, 31, 40, 48, 26],\n",
      "        [ 5, 10, 23, 27, 37, 38, 33],\n",
      "        [ 4, 15, 30, 37, 46, 48,  3]], device='cuda:0')\n",
      "tensor([ 7,  9, 21, 33, 38, 42, 45], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Create input/output sequences based on seq_len size of the window.\n",
    "# for each target create a sequence of seq_len preceeding inputs\n",
    "inputs = []\n",
    "targets = []\n",
    "for i in range(len(input_data) - seq_len):\n",
    "    seq = input_data[i:i+seq_len]           # shape: [seq_len, 7]\n",
    "    tgt = input_data[i+seq_len]             # shape: [7]\n",
    "    inputs.append(seq)\n",
    "    targets.append(tgt)\n",
    "\n",
    "inputs = np.array(inputs)    # shape: [num_samples, seq_len, 7]\n",
    "targets = np.array(targets)  # shape: [num_samples, 7]\n",
    "inputs = torch.tensor(inputs, dtype=torch.long).to(device)\n",
    "targets = torch.tensor(targets, dtype=torch.long).to(device)\n",
    "print(f\"inputs: {inputs.shape}, targets shape: {targets.shape}\")\n",
    "print(inputs[0])  # Display first input sequence\n",
    "print(targets[0])  # Display first target sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5883563",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for sequence modeling.\n",
    "    Each item is a tuple (X, y) where:\n",
    "      - X: input tensor of shape [seq_len, 7] (sequence of events)\n",
    "      - y: target tensor of shape [7] (next event to predict)\n",
    "    Used for batching input/output pairs for transformer models.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75a5445f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 4331\n",
      "First sample: (tensor([[ 3, 11, 12, 14, 41, 43, 13],\n",
      "        [ 8, 33, 36, 37, 39, 41,  9],\n",
      "        [ 1,  6, 23, 24, 27, 39, 34],\n",
      "        [ 3,  9, 10, 13, 20, 43, 34],\n",
      "        [ 5, 14, 21, 31, 34, 47, 45],\n",
      "        [ 8, 20, 21, 25, 31, 41, 33],\n",
      "        [18, 25, 28, 33, 36, 42,  7],\n",
      "        [ 7, 16, 17, 31, 40, 48, 26],\n",
      "        [ 5, 10, 23, 27, 37, 38, 33],\n",
      "        [ 4, 15, 30, 37, 46, 48,  3]], device='cuda:0'), tensor([ 7,  9, 21, 33, 38, 42, 45], device='cuda:0'))\n",
      "Last sample: (tensor([[ 4, 12, 19, 34, 40, 42,  5],\n",
      "        [ 5,  8, 13, 26, 44, 49, 47],\n",
      "        [11, 13, 15, 16, 38, 48, 25],\n",
      "        [ 7, 11, 23, 29, 44, 46, 42],\n",
      "        [ 1,  4,  5, 10, 37, 46, 24],\n",
      "        [15, 17, 21, 22, 38, 45, 26],\n",
      "        [ 4,  9, 11, 12, 42, 49, 41],\n",
      "        [ 7, 18, 23, 35, 48, 49, 19],\n",
      "        [24, 29, 31, 33, 36, 37, 21],\n",
      "        [ 3, 10, 12, 14, 36, 41,  1]], device='cuda:0'), tensor([ 5, 16, 17, 21, 41, 47,  6], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "# Create a dataset that has corresponding inputs and targets\n",
    "dataset = SequenceDataset(inputs, targets)\n",
    "# Create a dataloader for a defined batch size, shuffle is False because order is important\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "print(f\"Dataset length: {len(dataset)}\")\n",
    "print(f\"First sample: {dataset[0]}\")\n",
    "print(f\"Last sample: {dataset[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f87c944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SimpleTransformer model class\n",
    "class SimpleTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size=50, embed_dim=embedding_dim, num_heads=2, num_layers=1, num_outputs=6):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.ModuleList([nn.Linear(embed_dim, vocab_size) for _ in range(num_outputs)])\n",
    "        self.num_outputs = num_outputs\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, seq_len, 7]; used here for clarity and debugging\n",
    "        batch_size, seq_len, num_features = x.shape\n",
    "        # Embed each categorical value\n",
    "        x = self.embedding(x)  # [batch_size, seq_len, 7, embed_dim]\n",
    "        # Aggregate features for each event (mean or sum)\n",
    "        x = x.mean(dim=2)      # [batch_size, seq_len, embed_dim]\n",
    "        x = self.transformer(x)\n",
    "        x = x[:, -1, :]        # use last token's output\n",
    "        outs = [fc(x) for fc in self.fc]  # list of [batch_size, vocab_size]\n",
    "        return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8423b9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 20.2424\n",
      "Epoch 2/100, Loss: 19.5627\n",
      "Epoch 3/100, Loss: 19.4348\n",
      "Epoch 4/100, Loss: 19.2322\n",
      "Epoch 5/100, Loss: 18.9010\n",
      "Epoch 6/100, Loss: 18.3891\n",
      "Epoch 7/100, Loss: 17.7762\n",
      "Epoch 8/100, Loss: 17.0703\n",
      "Epoch 9/100, Loss: 16.2756\n",
      "Epoch 10/100, Loss: 15.4877\n",
      "Epoch 11/100, Loss: 14.6198\n",
      "Epoch 12/100, Loss: 13.8413\n",
      "Epoch 13/100, Loss: 13.0380\n",
      "Epoch 14/100, Loss: 12.3005\n",
      "Epoch 15/100, Loss: 11.5331\n",
      "Epoch 16/100, Loss: 10.8823\n",
      "Epoch 17/100, Loss: 10.2136\n",
      "Epoch 18/100, Loss: 9.6018\n",
      "Epoch 19/100, Loss: 9.0635\n",
      "Epoch 20/100, Loss: 8.6651\n",
      "Epoch 21/100, Loss: 8.1887\n",
      "Epoch 22/100, Loss: 7.7520\n",
      "Epoch 23/100, Loss: 7.4086\n",
      "Epoch 24/100, Loss: 7.0484\n",
      "Epoch 25/100, Loss: 6.7314\n",
      "Epoch 26/100, Loss: 6.4156\n",
      "Epoch 27/100, Loss: 6.1746\n",
      "Epoch 28/100, Loss: 5.9950\n",
      "Epoch 29/100, Loss: 5.7612\n",
      "Epoch 30/100, Loss: 5.4801\n",
      "Epoch 31/100, Loss: 5.3728\n",
      "Epoch 32/100, Loss: 5.1576\n",
      "Epoch 33/100, Loss: 4.9202\n",
      "Epoch 34/100, Loss: 4.7980\n",
      "Epoch 35/100, Loss: 4.6782\n",
      "Epoch 36/100, Loss: 4.5328\n",
      "Epoch 37/100, Loss: 4.4579\n",
      "Epoch 38/100, Loss: 4.1727\n",
      "Epoch 39/100, Loss: 4.2115\n",
      "Epoch 40/100, Loss: 4.0891\n",
      "Epoch 41/100, Loss: 3.9525\n",
      "Epoch 42/100, Loss: 3.7959\n",
      "Epoch 43/100, Loss: 3.7283\n",
      "Epoch 44/100, Loss: 3.6103\n",
      "Epoch 45/100, Loss: 3.5471\n",
      "Epoch 46/100, Loss: 3.4934\n",
      "Epoch 47/100, Loss: 3.3575\n",
      "Epoch 48/100, Loss: 3.2763\n",
      "Epoch 49/100, Loss: 3.2177\n",
      "Epoch 50/100, Loss: 3.1764\n",
      "Epoch 51/100, Loss: 3.1334\n",
      "Epoch 52/100, Loss: 3.0953\n",
      "Epoch 53/100, Loss: 3.0026\n",
      "Epoch 54/100, Loss: 2.9232\n",
      "Epoch 55/100, Loss: 2.8691\n",
      "Epoch 56/100, Loss: 2.8330\n",
      "Epoch 57/100, Loss: 2.7577\n",
      "Epoch 58/100, Loss: 2.7903\n",
      "Epoch 59/100, Loss: 2.7806\n",
      "Epoch 60/100, Loss: 2.7214\n",
      "Epoch 61/100, Loss: 2.6916\n",
      "Epoch 62/100, Loss: 2.6138\n",
      "Epoch 63/100, Loss: 2.6167\n",
      "Epoch 64/100, Loss: 2.5880\n",
      "Epoch 65/100, Loss: 2.6157\n",
      "Epoch 66/100, Loss: 2.5203\n",
      "Epoch 67/100, Loss: 2.3704\n",
      "Epoch 68/100, Loss: 2.3522\n",
      "Epoch 69/100, Loss: 2.4230\n",
      "Epoch 70/100, Loss: 2.3259\n",
      "Epoch 71/100, Loss: 2.3572\n",
      "Epoch 72/100, Loss: 2.3107\n",
      "Epoch 73/100, Loss: 2.2378\n",
      "Epoch 74/100, Loss: 2.2237\n",
      "Epoch 75/100, Loss: 2.2526\n",
      "Epoch 76/100, Loss: 2.2269\n",
      "Epoch 77/100, Loss: 2.1922\n",
      "Epoch 78/100, Loss: 2.1306\n",
      "Epoch 79/100, Loss: 2.1176\n",
      "Epoch 80/100, Loss: 2.0936\n",
      "Epoch 81/100, Loss: 2.0740\n",
      "Epoch 82/100, Loss: 2.0414\n",
      "Epoch 83/100, Loss: 2.0757\n",
      "Epoch 84/100, Loss: 2.0296\n",
      "Epoch 85/100, Loss: 2.0183\n",
      "Epoch 86/100, Loss: 2.0314\n",
      "Epoch 87/100, Loss: 1.9442\n",
      "Epoch 88/100, Loss: 1.9930\n",
      "Epoch 89/100, Loss: 1.9311\n",
      "Epoch 90/100, Loss: 1.8929\n",
      "Epoch 91/100, Loss: 1.8987\n",
      "Epoch 92/100, Loss: 1.8624\n",
      "Epoch 93/100, Loss: 1.7985\n",
      "Epoch 94/100, Loss: 1.8640\n",
      "Epoch 95/100, Loss: 1.7939\n",
      "Epoch 96/100, Loss: 1.8680\n",
      "Epoch 97/100, Loss: 1.8366\n",
      "Epoch 98/100, Loss: 1.8119\n",
      "Epoch 99/100, Loss: 1.7911\n",
      "Epoch 100/100, Loss: 1.7890\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the transformer model for training\n",
    "model = SimpleTransformer(num_outputs=6)  # 6 unique values\n",
    "model = model.to(device)  # Move model to CUDA if available\n",
    "\n",
    "# TensorBoard writer uses default directory ./runs\n",
    "# to view results run tensorboard --logdir runs\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# Training loop for the transformer model\n",
    "# Use CrossEntropyLoss for each output\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outs = model(batch_X)  # list of 6 outputs, each [batch_size, vocab_size]\n",
    "        # For each output, compute loss against the corresponding target value\n",
    "        loss = 0\n",
    "        for i in range(6):\n",
    "            loss += criterion(outs[i], batch_y[:, i])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "    writer.add_scalar('Loss/train', avg_loss, epoch)\n",
    "\n",
    "# Log hyperparameters and final loss to TensorBoard\n",
    "hparams = {\n",
    "    'seq_len': seq_len,\n",
    "    'num_epochs': num_epochs,\n",
    "    'batch_size': batch_size,\n",
    "    'embedding_dim': embedding_dim,\n",
    "    'learning_rate': learning_rate,\n",
    "}\n",
    "metrics = {\n",
    "    'final_loss': avg_loss\n",
    "}\n",
    "writer.add_hparams(hparams, metrics)\n",
    "\n",
    "print(\"Training complete.\")\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87dc1a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 5,  8, 13, 26, 44, 49, 47],\n",
      "         [11, 13, 15, 16, 38, 48, 25],\n",
      "         [ 7, 11, 23, 29, 44, 46, 42],\n",
      "         [ 1,  4,  5, 10, 37, 46, 24],\n",
      "         [15, 17, 21, 22, 38, 45, 26],\n",
      "         [ 4,  9, 11, 12, 42, 49, 41],\n",
      "         [ 7, 18, 23, 35, 48, 49, 19],\n",
      "         [24, 29, 31, 33, 36, 37, 21],\n",
      "         [ 3, 10, 12, 14, 36, 41,  1],\n",
      "         [ 5, 16, 17, 21, 41, 47,  6]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Prep last sequence of input data for inference\n",
    "last_seq = torch.tensor(input_data[-seq_len:], dtype=torch.long).unsqueeze(0).to(device)  # shape: [1, seq_len, 7]\n",
    "\n",
    "print(last_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b12c6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw model outputs (logits) for each predicted value:\n",
      "Predicted 6 unique values for the next event: [9, 13, 29, 31, 38, 37]\n"
     ]
    }
   ],
   "source": [
    "# Inference for the next event using the last seq_len inputs\n",
    "# Take the last sequence from the input data\n",
    "# last_seq = inputs[-1].unsqueeze(0).to(device)  # shape: [1, seq_len, 7], move to CUDA if available\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Pass the last sequence to the model\n",
    "    outs = model(last_seq)  # list of 6 outputs, each [1, vocab_size]\n",
    "    print(\"Raw model outputs (logits) for each predicted value:\")\n",
    "    # for i, out in enumerate(outs):\n",
    "    #     print(f\"Output {i+1}:\", out[0].cpu().numpy())\n",
    "    pred_vals = []\n",
    "    for out in outs:\n",
    "        # For each output, get the predicted category\n",
    "        val = torch.argmax(out[0])\n",
    "        pred_vals.append(val.item())\n",
    "    # Ensure uniqueness among the 6 predicted values\n",
    "    unique_pred = []\n",
    "    for val in pred_vals:\n",
    "        if val not in unique_pred and len(unique_pred) < 6:\n",
    "            unique_pred.append(val)\n",
    "    # If not enough unique, fill with remaining unused values\n",
    "    if len(unique_pred) < 6:\n",
    "        unused = set(range(50)) - set(unique_pred)\n",
    "        unique_pred += list(unused)[:6-len(unique_pred)]\n",
    "    print(f\"Predicted 6 unique values for the next event: {unique_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dab8054b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and info saved to ./saved_model\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model and all necessary info for later loading and inference\n",
    "import os\n",
    "save_dir = './saved_model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "model_path = os.path.join(save_dir, 'simple_transformer.pth')\n",
    "info_path = os.path.join(save_dir, 'model_info.pth')\n",
    "\n",
    "# Save model state dict\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "# Save hyperparameters and other info needed for loading\n",
    "model_info = {\n",
    "    'vocab_size': 50,\n",
    "    'embed_dim': embedding_dim,\n",
    "    'num_heads': 2,\n",
    "    'num_layers': 1,\n",
    "    'num_outputs': 6,\n",
    "    'seq_len': seq_len,\n",
    "    'data_columns': data_columns,\n",
    "}\n",
    "torch.save(model_info, info_path)\n",
    "\n",
    "print(f\"Model and info saved to {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ae5af3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleTransformer class definition saved to ./saved_model/simple_transformer.py\n"
     ]
    }
   ],
   "source": [
    "# Save the SimpleTransformer class definition to a Python file for reuse\n",
    "class_code = '''import torch.nn as nn\\n\\nclass SimpleTransformer(nn.Module):\\n    def __init__(self, vocab_size=50, embed_dim=32, num_heads=2, num_layers=1, num_outputs=6):\\n        super().__init__()\\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\\n        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, batch_first=True)\\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\\n        self.fc = nn.ModuleList([nn.Linear(embed_dim, vocab_size) for _ in range(num_outputs)])\\n        self.num_outputs = num_outputs\\n    def forward(self, x):\\n        batch_size, seq_len, num_features = x.shape\\n        x = self.embedding(x)  # [batch_size, seq_len, 7, embed_dim]\\n        x = x.mean(dim=2)      # [batch_size, seq_len, embed_dim]\\n        x = self.transformer(x)\\n        x = x[:, -1, :]        # use last token's output\\n        outs = [fc(x) for fc in self.fc]  # list of [batch_size, vocab_size]\\n        return outs\\n'''\n",
    "with open('./saved_model/simple_transformer.py', 'w') as f:\n",
    "    f.write(class_code)\n",
    "print('SimpleTransformer class definition saved to ./saved_model/simple_transformer.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
