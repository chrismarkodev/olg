{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ad964f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf90900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "seq_len = 10  # window size for input sequences\n",
    "data_columns = ['d1', 'd2', 'd3', 'd4', 'd5', 'd6', 'bonus']\n",
    "\n",
    "num_epochs = 100    # Epoch 100/100, Loss: 8.0247\n",
    "\n",
    "# learning_rate = 0.01   # Epoch 10/10, Loss: 19.3940\n",
    "learning_rate = 0.001    # original Epoch 10/10, Loss: 18.2901\n",
    "# batch size hyperparameter\n",
    "batch_size = 32\n",
    "# key hyperparameter that controls the size of the embedding vectors for categorical values\n",
    "embedding_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6630e8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data shape: (4353, 7)\n",
      "input data type: int64\n",
      "[[ 3 11 12 14 41 43 13]\n",
      " [ 8 33 36 37 39 41  9]\n",
      " [ 1  6 23 24 27 39 34]\n",
      " [ 3  9 10 13 20 43 34]\n",
      " [ 5 14 21 31 34 47 45]]\n",
      "...\n",
      "[[ 9 10 12 17 46 49 30]\n",
      " [ 1  7 15 19 36 40 47]\n",
      " [26 27 30 38 47 48 43]\n",
      " [24 31 37 41 45 46 16]\n",
      " [17 22 24 40 42 46 29]]\n",
      "Data loaded and preprocessed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Read and preprocess data\n",
    "file_path = '../data/data_all_l649.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.drop(columns=['date'])\n",
    "input_data = df[data_columns].values.astype(int)\n",
    "print(f\"input data shape: {input_data.shape}\")\n",
    "print(f\"input data type: {input_data.dtype}\")\n",
    "print(input_data[:5])  # Display first 5 rows of labels\n",
    "print('...')\n",
    "print(input_data[-5:])  # Display last 5 rows of labels\n",
    "print(\"Data loaded and preprocessed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e080d5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and set device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca01ef02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: torch.Size([4343, 10, 7]), targets shape: torch.Size([4343, 7])\n",
      "tensor([[ 3, 11, 12, 14, 41, 43, 13],\n",
      "        [ 8, 33, 36, 37, 39, 41,  9],\n",
      "        [ 1,  6, 23, 24, 27, 39, 34],\n",
      "        [ 3,  9, 10, 13, 20, 43, 34],\n",
      "        [ 5, 14, 21, 31, 34, 47, 45],\n",
      "        [ 8, 20, 21, 25, 31, 41, 33],\n",
      "        [18, 25, 28, 33, 36, 42,  7],\n",
      "        [ 7, 16, 17, 31, 40, 48, 26],\n",
      "        [ 5, 10, 23, 27, 37, 38, 33],\n",
      "        [ 4, 15, 30, 37, 46, 48,  3]], device='cuda:0')\n",
      "tensor([ 7,  9, 21, 33, 38, 42, 45], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Create input/output sequences based on seq_len size of the window.\n",
    "# for each target create a sequence of seq_len preceeding inputs\n",
    "inputs = []\n",
    "targets = []\n",
    "for i in range(len(input_data) - seq_len):\n",
    "    seq = input_data[i:i+seq_len]           # shape: [seq_len, 7]\n",
    "    tgt = input_data[i+seq_len]             # shape: [7]\n",
    "    inputs.append(seq)\n",
    "    targets.append(tgt)\n",
    "\n",
    "inputs = np.array(inputs)    # shape: [num_samples, seq_len, 7]\n",
    "targets = np.array(targets)  # shape: [num_samples, 7]\n",
    "inputs = torch.tensor(inputs, dtype=torch.long).to(device)\n",
    "targets = torch.tensor(targets, dtype=torch.long).to(device)\n",
    "print(f\"inputs: {inputs.shape}, targets shape: {targets.shape}\")\n",
    "print(inputs[0])  # Display first input sequence\n",
    "print(targets[0])  # Display first target sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5883563",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for sequence modeling.\n",
    "    Each item is a tuple (X, y) where:\n",
    "      - X: input tensor of shape [seq_len, 7] (sequence of events)\n",
    "      - y: target tensor of shape [7] (next event to predict)\n",
    "    Used for batching input/output pairs for transformer models.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75a5445f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 4343\n",
      "First sample: (tensor([[ 3, 11, 12, 14, 41, 43, 13],\n",
      "        [ 8, 33, 36, 37, 39, 41,  9],\n",
      "        [ 1,  6, 23, 24, 27, 39, 34],\n",
      "        [ 3,  9, 10, 13, 20, 43, 34],\n",
      "        [ 5, 14, 21, 31, 34, 47, 45],\n",
      "        [ 8, 20, 21, 25, 31, 41, 33],\n",
      "        [18, 25, 28, 33, 36, 42,  7],\n",
      "        [ 7, 16, 17, 31, 40, 48, 26],\n",
      "        [ 5, 10, 23, 27, 37, 38, 33],\n",
      "        [ 4, 15, 30, 37, 46, 48,  3]], device='cuda:0'), tensor([ 7,  9, 21, 33, 38, 42, 45], device='cuda:0'))\n",
      "Last sample: (tensor([[14, 22, 24, 28, 34, 35,  4],\n",
      "        [12, 25, 26, 38, 39, 41, 16],\n",
      "        [11, 25, 30, 35, 46, 49, 37],\n",
      "        [13, 21, 23, 33, 35, 45,  1],\n",
      "        [ 3, 12, 23, 27, 33, 45, 22],\n",
      "        [ 7,  9, 19, 34, 39, 44, 38],\n",
      "        [ 9, 10, 12, 17, 46, 49, 30],\n",
      "        [ 1,  7, 15, 19, 36, 40, 47],\n",
      "        [26, 27, 30, 38, 47, 48, 43],\n",
      "        [24, 31, 37, 41, 45, 46, 16]], device='cuda:0'), tensor([17, 22, 24, 40, 42, 46, 29], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "# Create a dataset that has corresponding inputs and targets\n",
    "dataset = SequenceDataset(inputs, targets)\n",
    "# Create a dataloader for a defined batch size, shuffle is False because order is important\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "print(f\"Dataset length: {len(dataset)}\")\n",
    "print(f\"First sample: {dataset[0]}\")\n",
    "print(f\"Last sample: {dataset[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f87c944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SimpleLSTM model class\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size=50, embed_dim=embedding_dim, hidden_dim=128, num_layers=1, num_outputs=6):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embed_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.ModuleList([nn.Linear(hidden_dim, vocab_size) for _ in range(num_outputs)])\n",
    "        self.num_outputs = num_outputs\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, seq_len, 7]\n",
    "        batch_size, seq_len, num_features = x.shape\n",
    "        # Embed each categorical value\n",
    "        x = self.embedding(x)  # [batch_size, seq_len, 7, embed_dim]\n",
    "        # Aggregate features for each event (mean or sum)\n",
    "        x = x.mean(dim=2)      # [batch_size, seq_len, embed_dim]\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        x = lstm_out[:, -1, :]  # use last time step's output\n",
    "        outs = [fc(x) for fc in self.fc]  # list of [batch_size, vocab_size]\n",
    "        return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8423b9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 20.0738\n",
      "Epoch 2/100, Loss: 19.5165\n",
      "Epoch 2/100, Loss: 19.5165\n",
      "Epoch 3/100, Loss: 19.4569\n",
      "Epoch 3/100, Loss: 19.4569\n",
      "Epoch 4/100, Loss: 19.3918\n",
      "Epoch 4/100, Loss: 19.3918\n",
      "Epoch 5/100, Loss: 19.3048\n",
      "Epoch 5/100, Loss: 19.3048\n",
      "Epoch 6/100, Loss: 19.2109\n",
      "Epoch 6/100, Loss: 19.2109\n",
      "Epoch 7/100, Loss: 19.1089\n",
      "Epoch 7/100, Loss: 19.1089\n",
      "Epoch 8/100, Loss: 18.9966\n",
      "Epoch 8/100, Loss: 18.9966\n",
      "Epoch 9/100, Loss: 18.8747\n",
      "Epoch 9/100, Loss: 18.8747\n",
      "Epoch 10/100, Loss: 18.7459\n",
      "Epoch 10/100, Loss: 18.7459\n",
      "Epoch 11/100, Loss: 18.6079\n",
      "Epoch 11/100, Loss: 18.6079\n",
      "Epoch 12/100, Loss: 18.4566\n",
      "Epoch 12/100, Loss: 18.4566\n",
      "Epoch 13/100, Loss: 18.2929\n",
      "Epoch 13/100, Loss: 18.2929\n",
      "Epoch 14/100, Loss: 18.1226\n",
      "Epoch 14/100, Loss: 18.1226\n",
      "Epoch 15/100, Loss: 17.9310\n",
      "Epoch 15/100, Loss: 17.9310\n",
      "Epoch 16/100, Loss: 17.7260\n",
      "Epoch 16/100, Loss: 17.7260\n",
      "Epoch 17/100, Loss: 17.5301\n",
      "Epoch 17/100, Loss: 17.5301\n",
      "Epoch 18/100, Loss: 17.3446\n",
      "Epoch 18/100, Loss: 17.3446\n",
      "Epoch 19/100, Loss: 17.1432\n",
      "Epoch 19/100, Loss: 17.1432\n",
      "Epoch 20/100, Loss: 16.9015\n",
      "Epoch 20/100, Loss: 16.9015\n",
      "Epoch 21/100, Loss: 16.6474\n",
      "Epoch 21/100, Loss: 16.6474\n",
      "Epoch 22/100, Loss: 16.3826\n",
      "Epoch 22/100, Loss: 16.3826\n",
      "Epoch 23/100, Loss: 16.0781\n",
      "Epoch 23/100, Loss: 16.0781\n",
      "Epoch 24/100, Loss: 15.7922\n",
      "Epoch 24/100, Loss: 15.7922\n",
      "Epoch 25/100, Loss: 15.4904\n",
      "Epoch 25/100, Loss: 15.4904\n",
      "Epoch 26/100, Loss: 15.1738\n",
      "Epoch 26/100, Loss: 15.1738\n",
      "Epoch 27/100, Loss: 14.9012\n",
      "Epoch 27/100, Loss: 14.9012\n",
      "Epoch 28/100, Loss: 14.5980\n",
      "Epoch 28/100, Loss: 14.5980\n",
      "Epoch 29/100, Loss: 14.2113\n",
      "Epoch 29/100, Loss: 14.2113\n",
      "Epoch 30/100, Loss: 13.9176\n",
      "Epoch 30/100, Loss: 13.9176\n",
      "Epoch 31/100, Loss: 13.5864\n",
      "Epoch 31/100, Loss: 13.5864\n",
      "Epoch 32/100, Loss: 13.2525\n",
      "Epoch 32/100, Loss: 13.2525\n",
      "Epoch 33/100, Loss: 12.9255\n",
      "Epoch 33/100, Loss: 12.9255\n",
      "Epoch 34/100, Loss: 12.6153\n",
      "Epoch 34/100, Loss: 12.6153\n",
      "Epoch 35/100, Loss: 12.2795\n",
      "Epoch 35/100, Loss: 12.2795\n",
      "Epoch 36/100, Loss: 11.9224\n",
      "Epoch 36/100, Loss: 11.9224\n",
      "Epoch 37/100, Loss: 11.5973\n",
      "Epoch 37/100, Loss: 11.5973\n",
      "Epoch 38/100, Loss: 11.2899\n",
      "Epoch 38/100, Loss: 11.2899\n",
      "Epoch 39/100, Loss: 10.9683\n",
      "Epoch 39/100, Loss: 10.9683\n",
      "Epoch 40/100, Loss: 10.6886\n",
      "Epoch 40/100, Loss: 10.6886\n",
      "Epoch 41/100, Loss: 10.4448\n",
      "Epoch 41/100, Loss: 10.4448\n",
      "Epoch 42/100, Loss: 10.1974\n",
      "Epoch 42/100, Loss: 10.1974\n",
      "Epoch 43/100, Loss: 9.9373\n",
      "Epoch 43/100, Loss: 9.9373\n",
      "Epoch 44/100, Loss: 9.6991\n",
      "Epoch 44/100, Loss: 9.6991\n",
      "Epoch 45/100, Loss: 9.4382\n",
      "Epoch 45/100, Loss: 9.4382\n",
      "Epoch 46/100, Loss: 9.1872\n",
      "Epoch 46/100, Loss: 9.1872\n",
      "Epoch 47/100, Loss: 8.9695\n",
      "Epoch 47/100, Loss: 8.9695\n",
      "Epoch 48/100, Loss: 8.7561\n",
      "Epoch 48/100, Loss: 8.7561\n",
      "Epoch 49/100, Loss: 8.4977\n",
      "Epoch 49/100, Loss: 8.4977\n",
      "Epoch 50/100, Loss: 8.3146\n",
      "Epoch 50/100, Loss: 8.3146\n",
      "Epoch 51/100, Loss: 8.0964\n",
      "Epoch 51/100, Loss: 8.0964\n",
      "Epoch 52/100, Loss: 7.8784\n",
      "Epoch 52/100, Loss: 7.8784\n",
      "Epoch 53/100, Loss: 7.6111\n",
      "Epoch 53/100, Loss: 7.6111\n",
      "Epoch 54/100, Loss: 7.4329\n",
      "Epoch 54/100, Loss: 7.4329\n",
      "Epoch 55/100, Loss: 7.3012\n",
      "Epoch 55/100, Loss: 7.3012\n",
      "Epoch 56/100, Loss: 7.1094\n",
      "Epoch 56/100, Loss: 7.1094\n",
      "Epoch 57/100, Loss: 6.9148\n",
      "Epoch 57/100, Loss: 6.9148\n",
      "Epoch 58/100, Loss: 6.7143\n",
      "Epoch 58/100, Loss: 6.7143\n",
      "Epoch 59/100, Loss: 6.4782\n",
      "Epoch 59/100, Loss: 6.4782\n",
      "Epoch 60/100, Loss: 6.2647\n",
      "Epoch 60/100, Loss: 6.2647\n",
      "Epoch 61/100, Loss: 6.0261\n",
      "Epoch 61/100, Loss: 6.0261\n",
      "Epoch 62/100, Loss: 5.8616\n",
      "Epoch 62/100, Loss: 5.8616\n",
      "Epoch 63/100, Loss: 5.7158\n",
      "Epoch 63/100, Loss: 5.7158\n",
      "Epoch 64/100, Loss: 5.5748\n",
      "Epoch 64/100, Loss: 5.5748\n",
      "Epoch 65/100, Loss: 5.5010\n",
      "Epoch 65/100, Loss: 5.5010\n",
      "Epoch 66/100, Loss: 5.3880\n",
      "Epoch 66/100, Loss: 5.3880\n",
      "Epoch 67/100, Loss: 5.2538\n",
      "Epoch 67/100, Loss: 5.2538\n",
      "Epoch 68/100, Loss: 5.0929\n",
      "Epoch 68/100, Loss: 5.0929\n",
      "Epoch 69/100, Loss: 4.8963\n",
      "Epoch 69/100, Loss: 4.8963\n",
      "Epoch 70/100, Loss: 4.7171\n",
      "Epoch 70/100, Loss: 4.7171\n",
      "Epoch 71/100, Loss: 4.5571\n",
      "Epoch 71/100, Loss: 4.5571\n",
      "Epoch 72/100, Loss: 4.3935\n",
      "Epoch 72/100, Loss: 4.3935\n",
      "Epoch 73/100, Loss: 4.2820\n",
      "Epoch 73/100, Loss: 4.2820\n",
      "Epoch 74/100, Loss: 4.1955\n",
      "Epoch 74/100, Loss: 4.1955\n",
      "Epoch 75/100, Loss: 4.1097\n",
      "Epoch 75/100, Loss: 4.1097\n",
      "Epoch 76/100, Loss: 4.0225\n",
      "Epoch 76/100, Loss: 4.0225\n",
      "Epoch 77/100, Loss: 3.9261\n",
      "Epoch 77/100, Loss: 3.9261\n",
      "Epoch 78/100, Loss: 3.8585\n",
      "Epoch 78/100, Loss: 3.8585\n",
      "Epoch 79/100, Loss: 3.6998\n",
      "Epoch 79/100, Loss: 3.6998\n",
      "Epoch 80/100, Loss: 3.5822\n",
      "Epoch 80/100, Loss: 3.5822\n",
      "Epoch 81/100, Loss: 3.4326\n",
      "Epoch 81/100, Loss: 3.4326\n",
      "Epoch 82/100, Loss: 3.3001\n",
      "Epoch 82/100, Loss: 3.3001\n",
      "Epoch 83/100, Loss: 3.1845\n",
      "Epoch 83/100, Loss: 3.1845\n",
      "Epoch 84/100, Loss: 3.0784\n",
      "Epoch 84/100, Loss: 3.0784\n",
      "Epoch 85/100, Loss: 2.9815\n",
      "Epoch 85/100, Loss: 2.9815\n",
      "Epoch 86/100, Loss: 2.9426\n",
      "Epoch 86/100, Loss: 2.9426\n",
      "Epoch 87/100, Loss: 2.9017\n",
      "Epoch 87/100, Loss: 2.9017\n",
      "Epoch 88/100, Loss: 2.8091\n",
      "Epoch 88/100, Loss: 2.8091\n",
      "Epoch 89/100, Loss: 2.7134\n",
      "Epoch 89/100, Loss: 2.7134\n",
      "Epoch 90/100, Loss: 2.6394\n",
      "Epoch 90/100, Loss: 2.6394\n",
      "Epoch 91/100, Loss: 2.5476\n",
      "Epoch 91/100, Loss: 2.5476\n",
      "Epoch 92/100, Loss: 2.4229\n",
      "Epoch 92/100, Loss: 2.4229\n",
      "Epoch 93/100, Loss: 2.3445\n",
      "Epoch 93/100, Loss: 2.3445\n",
      "Epoch 94/100, Loss: 2.3837\n",
      "Epoch 94/100, Loss: 2.3837\n",
      "Epoch 95/100, Loss: 2.3866\n",
      "Epoch 95/100, Loss: 2.3866\n",
      "Epoch 96/100, Loss: 2.3027\n",
      "Epoch 96/100, Loss: 2.3027\n",
      "Epoch 97/100, Loss: 2.2144\n",
      "Epoch 97/100, Loss: 2.2144\n",
      "Epoch 98/100, Loss: 2.1027\n",
      "Epoch 98/100, Loss: 2.1027\n",
      "Epoch 99/100, Loss: 2.0240\n",
      "Epoch 99/100, Loss: 2.0240\n",
      "Epoch 100/100, Loss: 1.9482\n",
      "Training complete.\n",
      "Epoch 100/100, Loss: 1.9482\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the LSTM model for training\n",
    "model = SimpleLSTM(num_outputs=6)  # 6 unique values\n",
    "model = model.to(device)  # Move model to CUDA if available\n",
    "\n",
    "# TensorBoard writer uses default directory ./runs\n",
    "# to view results run tensorboard --logdir runs\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# Training loop for the LSTM model\n",
    "# Use CrossEntropyLoss for each output\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outs = model(batch_X)  # list of 6 outputs, each [batch_size, vocab_size]\n",
    "        # For each output, compute loss against the corresponding target value\n",
    "        loss = 0\n",
    "        for i in range(6):\n",
    "            loss += criterion(outs[i], batch_y[:, i])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "    writer.add_scalar('Loss/train', avg_loss, epoch)\n",
    "\n",
    "# Log hyperparameters and final loss to TensorBoard\n",
    "hparams = {\n",
    "    'seq_len': seq_len,\n",
    "    'num_epochs': num_epochs,\n",
    "    'batch_size': batch_size,\n",
    "    'embedding_dim': embedding_dim,\n",
    "    'learning_rate': learning_rate,\n",
    "}\n",
    "metrics = {\n",
    "    'final_loss': avg_loss\n",
    "}\n",
    "writer.add_hparams(hparams, metrics)\n",
    "\n",
    "print(\"Training complete.\")\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87dc1a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[12, 25, 26, 38, 39, 41, 16],\n",
      "         [11, 25, 30, 35, 46, 49, 37],\n",
      "         [13, 21, 23, 33, 35, 45,  1],\n",
      "         [ 3, 12, 23, 27, 33, 45, 22],\n",
      "         [ 7,  9, 19, 34, 39, 44, 38],\n",
      "         [ 9, 10, 12, 17, 46, 49, 30],\n",
      "         [ 1,  7, 15, 19, 36, 40, 47],\n",
      "         [26, 27, 30, 38, 47, 48, 43],\n",
      "         [24, 31, 37, 41, 45, 46, 16],\n",
      "         [17, 22, 24, 40, 42, 46, 29]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Prep last sequence of input data for inference\n",
    "last_seq = torch.tensor(input_data[-seq_len:], dtype=torch.long).unsqueeze(0).to(device)  # shape: [1, seq_len, 7]\n",
    "\n",
    "print(last_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b12c6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 6 unique values for the next event: [5, 7, 35, 46, 43, 0]\n"
     ]
    }
   ],
   "source": [
    "# Inference for the next event using the last seq_len inputs\n",
    "# Take the last sequence from the input data\n",
    "# last_seq = inputs[-1].unsqueeze(0).to(device)  # shape: [1, seq_len, 7], move to CUDA if available\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Pass the last sequence to the model\n",
    "    outs = model(last_seq)  # list of 6 outputs, each [1, vocab_size]\n",
    "    # print(\"Raw model outputs (logits) for each predicted value:\")\n",
    "    # for i, out in enumerate(outs):\n",
    "    #     print(f\"Output {i+1}:\", out[0].cpu().numpy())\n",
    "    pred_vals = []\n",
    "    for out in outs:\n",
    "        # For each output, get the predicted category\n",
    "        val = torch.argmax(out[0])\n",
    "        pred_vals.append(val.item())\n",
    "    # Ensure uniqueness among the 6 predicted values\n",
    "    unique_pred = []\n",
    "    for val in pred_vals:\n",
    "        if val not in unique_pred and len(unique_pred) < 6:\n",
    "            unique_pred.append(val)\n",
    "    # If not enough unique, fill with remaining unused values\n",
    "    if len(unique_pred) < 6:\n",
    "        unused = set(range(50)) - set(unique_pred)\n",
    "        unique_pred += list(unused)[:6-len(unique_pred)]\n",
    "    print(f\"Predicted 6 unique values for the next event: {unique_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dab8054b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM model and info saved to ./saved_model\n",
      "SimpleLSTM class definition saved to ./saved_model\\simplelstm_class.py\n"
     ]
    }
   ],
   "source": [
    "# Save the trained LSTM model and all necessary info for later loading and inference\n",
    "import os\n",
    "save_dir = './saved_model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "model_path = os.path.join(save_dir, 'simplelstm_model.pth')\n",
    "info_path = os.path.join(save_dir, 'simplelstm_model_info.pth')\n",
    "\n",
    "# Save model state dict\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "# Save hyperparameters and other info needed for loading\n",
    "model_info = {\n",
    "    'vocab_size': 50,\n",
    "    'embed_dim': embedding_dim,\n",
    "    'hidden_dim': 128,\n",
    "    'num_layers': 1,\n",
    "    'num_outputs': 6,\n",
    "    'seq_len': seq_len,\n",
    "    'data_columns': data_columns,\n",
    "}\n",
    "torch.save(model_info, info_path)\n",
    "\n",
    "print(f\"LSTM model and info saved to {save_dir}\")\n",
    "\n",
    "# Save the SimpleLSTM class definition to a Python file for reuse\n",
    "class_code = '''import torch.nn as nn\\n\\nclass SimpleLSTM(nn.Module):\\n    def __init__(self, vocab_size=50, embed_dim=64, hidden_dim=128, num_layers=1, num_outputs=6):\\n        super().__init__()\\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\\n        self.lstm = nn.LSTM(input_size=embed_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\\n        self.fc = nn.ModuleList([nn.Linear(hidden_dim, vocab_size) for _ in range(num_outputs)])\\n        self.num_outputs = num_outputs\\n    def forward(self, x):\\n        batch_size, seq_len, num_features = x.shape\\n        x = self.embedding(x)  # [batch_size, seq_len, 7, embed_dim]\\n        x = x.mean(dim=2)      # [batch_size, seq_len, embed_dim]\\n        lstm_out, _ = self.lstm(x)\\n        x = lstm_out[:, -1, :]  # use last time step's output\\n        outs = [fc(x) for fc in self.fc]  # list of [batch_size, vocab_size]\\n        return outs\\n'''\n",
    "class_path = os.path.join(save_dir, 'simplelstm_class.py')\n",
    "with open(class_path, 'w') as f:\n",
    "    f.write(class_code)\n",
    "print(f'SimpleLSTM class definition saved to {class_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
