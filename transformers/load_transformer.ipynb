{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa70de9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model and info for inference\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce17f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check if CUDA is available and set device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682ae9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SimpleTransformer model class (required for loading the model)\n",
    "import torch.nn as nn\n",
    "class SimpleTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size=50, embed_dim=32, num_heads=2, num_layers=1, num_outputs=6):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.ModuleList([nn.Linear(embed_dim, vocab_size) for _ in range(num_outputs)])\n",
    "        self.num_outputs = num_outputs\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, num_features = x.shape\n",
    "        x = self.embedding(x)  # [batch_size, seq_len, 7, embed_dim]\n",
    "        x = x.mean(dim=2)      # [batch_size, seq_len, embed_dim]\n",
    "        x = self.transformer(x)\n",
    "        x = x[:, -1, :]        # use last token's output\n",
    "        outs = [fc(x) for fc in self.fc]  # list of [batch_size, vocab_size]\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1454187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to saved files\n",
    "save_dir = './saved_model'\n",
    "model_path = os.path.join(save_dir, 'simple_transformer.pth')\n",
    "info_path = os.path.join(save_dir, 'model_info.pth')\n",
    "\n",
    "# Load model info (hyperparameters, etc.)\n",
    "model_info = torch.load(info_path)\n",
    "print(\"Loaded model info:\", model_info)\n",
    "\n",
    "# Recreate the model with loaded hyperparameters\n",
    "model = SimpleTransformer(\n",
    "    vocab_size=model_info['vocab_size'],\n",
    "    embed_dim=model_info['embed_dim'],\n",
    "    num_heads=model_info['num_heads'],\n",
    "    num_layers=model_info['num_layers'],\n",
    "    num_outputs=model_info['num_outputs']\n",
    "    # seq_len and data_columns are for data prep, not model init\n",
    "    # You can use them for preparing inference input\n",
    "    ).to(device)\n",
    "\n",
    "# Load model weights\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "print(\"Model loaded and ready for inference.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
